{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TQTT9x-6d2JI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8a346b2-1bfc-4d8e-94b4-b3fd302e5754"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "from scipy import sparse\n",
        "from sklearn import linear_model\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import operator\n",
        "import nltk\n",
        "import math\n",
        "from scipy.stats import norm\n",
        "import nltk\n",
        "nltk.download('punkt_tab')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bJuo3BAR5r6z"
      },
      "outputs": [],
      "source": [
        "def load_ordinal_data(filename, ordering):\n",
        "    X = []\n",
        "    Y = []\n",
        "    orig_Y=[]\n",
        "    for ordinal in ordering:\n",
        "        Y.append([])\n",
        "\n",
        "    with open(filename, encoding=\"utf-8\") as file:\n",
        "        for line in file:\n",
        "            cols = line.split(\"\\t\")\n",
        "            idd = cols[0]\n",
        "            label = cols[1].strip()\n",
        "            text = cols[2]\n",
        "\n",
        "            X.append(text)\n",
        "\n",
        "            index=ordering.index(label)\n",
        "            for i in range(len(ordering)):\n",
        "                if index > i:\n",
        "                    Y[i].append(1)\n",
        "                else:\n",
        "                    Y[i].append(0)\n",
        "            orig_Y.append(label)\n",
        "\n",
        "    return X, Y, orig_Y\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIob19ddLl1P"
      },
      "source": [
        "#### Default BoW Ordinal Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zNQbeYBT5r6z"
      },
      "outputs": [],
      "source": [
        "class OrdinalClassifier:\n",
        "\n",
        "    def __init__(self, ordinal_values, feature_method, trainX, trainY, devX, devY, testX, testY, orig_trainY, orig_devY, orig_testY):\n",
        "        self.ordinal_values=ordinal_values\n",
        "        self.feature_vocab = {}\n",
        "        self.feature_method = feature_method\n",
        "        self.min_feature_count=2\n",
        "        self.log_regs = [None]* (len(self.ordinal_values)-1)\n",
        "\n",
        "        self.trainY=trainY\n",
        "        self.devY=devY\n",
        "        self.testY=testY\n",
        "\n",
        "        self.orig_trainY=orig_trainY\n",
        "        self.orig_devY=orig_devY\n",
        "        self.orig_testY=orig_testY\n",
        "\n",
        "        self.trainX = self.process(trainX, training=True)\n",
        "        self.devX = self.process(devX, training=False)\n",
        "        self.testX = self.process(testX, training=False)\n",
        "\n",
        "    # Featurize entire dataset\n",
        "    def featurize(self, data):\n",
        "        featurized_data = []\n",
        "        for text in data:\n",
        "            feats = self.feature_method(text)\n",
        "            featurized_data.append(feats)\n",
        "        return featurized_data\n",
        "\n",
        "    # Read dataset and returned featurized representation as sparse matrix + label array\n",
        "    def process(self, X_data, training = False):\n",
        "\n",
        "        data = self.featurize(X_data)\n",
        "\n",
        "        if training:\n",
        "            fid = 0\n",
        "            feature_doc_count = Counter()\n",
        "            for feats in data:\n",
        "                for feat in feats:\n",
        "                    feature_doc_count[feat]+= 1\n",
        "\n",
        "            for feat in feature_doc_count:\n",
        "                if feature_doc_count[feat] >= self.min_feature_count:\n",
        "                    self.feature_vocab[feat] = fid\n",
        "                    fid += 1\n",
        "\n",
        "        F = len(self.feature_vocab)\n",
        "        D = len(data)\n",
        "        X = sparse.dok_matrix((D, F))\n",
        "        for idx, feats in enumerate(data):\n",
        "            for feat in feats:\n",
        "                if feat in self.feature_vocab:\n",
        "                    X[idx, self.feature_vocab[feat]] = feats[feat]\n",
        "\n",
        "        return X\n",
        "\n",
        "\n",
        "    def train(self):\n",
        "        (D,F) = self.trainX.shape\n",
        "\n",
        "\n",
        "        for idx, ordinal_value in enumerate(self.ordinal_values[:-1]):\n",
        "            best_dev_accuracy=0\n",
        "            best_model=None\n",
        "            for C in [0.1, 1, 10, 100]:\n",
        "\n",
        "                log_reg = linear_model.LogisticRegression(C = C, max_iter=1000)\n",
        "                log_reg.fit(self.trainX, self.trainY[idx])\n",
        "                development_accuracy = log_reg.score(self.devX, self.devY[idx])\n",
        "                if development_accuracy > best_dev_accuracy:\n",
        "                    best_dev_accuracy=development_accuracy\n",
        "                    best_model=log_reg\n",
        "\n",
        "\n",
        "            self.log_regs[idx]=best_model\n",
        "\n",
        "    def test(self):\n",
        "        cor=tot=0\n",
        "        counts=Counter()\n",
        "        preds=[None]*(len(self.ordinal_values)-1)\n",
        "        for idx, ordinal_value in enumerate(self.ordinal_values[:-1]):\n",
        "            preds[idx]=self.log_regs[idx].predict_proba(self.testX)[:,1]\n",
        "\n",
        "        preds=np.array(preds)\n",
        "\n",
        "        for data_point in range(len(preds[0])):\n",
        "\n",
        "\n",
        "            ordinal_preds=np.zeros(len(self.ordinal_values))\n",
        "            for ordinal in range(len(self.ordinal_values)-1):\n",
        "                if ordinal == 0:\n",
        "                    ordinal_preds[ordinal]=1-preds[ordinal][data_point]\n",
        "                else:\n",
        "                    ordinal_preds[ordinal]=preds[ordinal-1][data_point]-preds[ordinal][data_point]\n",
        "\n",
        "            ordinal_preds[len(self.ordinal_values)-1]=preds[len(preds)-1][data_point]\n",
        "\n",
        "            prediction=np.argmax(ordinal_preds)\n",
        "            counts[prediction]+=1\n",
        "            if prediction == self.ordinal_values.index(self.orig_testY[data_point]):\n",
        "                cor+=1\n",
        "            tot+=1\n",
        "\n",
        "        return cor/tot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SICAt-09Ll1Q"
      },
      "source": [
        "#### Modified TF-IDF Ordinal Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "mJvtWl3VLl1R"
      },
      "outputs": [],
      "source": [
        "class OrdinalClassifierTFIDF:\n",
        "\n",
        "    def __init__(self, ordinal_values, feature_method, trainX, trainY, devX, devY, testX, testY, orig_trainY, orig_devY, orig_testY):\n",
        "        self.ordinal_values=ordinal_values\n",
        "        self.feature_vocab = {}\n",
        "        self.feature_method = feature_method\n",
        "        self.min_feature_count=2\n",
        "        self.log_regs = [None]* (len(self.ordinal_values)-1)\n",
        "\n",
        "        # --- Added for TF-IDF ---\n",
        "        self.doc_freq = Counter()\n",
        "        self.idf_values = {}\n",
        "        self.N_train = 0\n",
        "\n",
        "        self.trainY=trainY\n",
        "        self.devY=devY\n",
        "        self.testY=testY\n",
        "\n",
        "        self.orig_trainY=orig_trainY\n",
        "        self.orig_devY=orig_devY\n",
        "        self.orig_testY=orig_testY\n",
        "\n",
        "        self.trainX = self.process(trainX, training=True)\n",
        "        self.devX = self.process(devX, training=False)\n",
        "        self.testX = self.process(testX, training=False)\n",
        "\n",
        "    # Featurize entire dataset\n",
        "    def featurize(self, data):\n",
        "        featurized_data = []\n",
        "        for text in data:\n",
        "            feats = self.feature_method(text)\n",
        "            featurized_data.append(feats)\n",
        "        return featurized_data\n",
        "\n",
        "    def process(self, X_data, training = False):\n",
        "\n",
        "        data = self.featurize(X_data)\n",
        "\n",
        "        if training:\n",
        "            self.N_train = len(data) # Store total number of training documents\n",
        "            fid = 0\n",
        "            # --- Calculate Document Frequency (DF) ---\n",
        "            for feats in data:\n",
        "                for feat in set(feats.keys()):\n",
        "                    self.doc_freq[feat] += 1\n",
        "\n",
        "            # --- Filter features based on DF and build vocab ---\n",
        "            for feat in self.doc_freq:\n",
        "                if self.doc_freq[feat] >= self.min_feature_count:\n",
        "                    if feat not in self.feature_vocab:\n",
        "                         self.feature_vocab[feat] = fid\n",
        "                         fid += 1\n",
        "\n",
        "            # --- Calculate IDF ---\n",
        "            for feat, _ in self.feature_vocab.items():\n",
        "                self.idf_values[feat] = math.log(self.N_train / (self.doc_freq[feat] + 1))\n",
        "\n",
        "\n",
        "        F = len(self.feature_vocab)\n",
        "        D = len(data)\n",
        "        X = sparse.dok_matrix((D, F))\n",
        "        for idx, feats in enumerate(data):\n",
        "            for feat in feats:\n",
        "                if feat in self.feature_vocab:\n",
        "                    # --- Apply TF-IDF weight ---\n",
        "                    tf = feats[feat]\n",
        "                    idf = self.idf_values.get(feat, 0)\n",
        "                    X[idx, self.feature_vocab[feat]] = tf * idf\n",
        "\n",
        "        return X\n",
        "\n",
        "\n",
        "    def train(self):\n",
        "        (D,F) = self.trainX.shape\n",
        "\n",
        "\n",
        "        for idx, ordinal_value in enumerate(self.ordinal_values[:-1]):\n",
        "            best_dev_accuracy=0\n",
        "            best_model=None\n",
        "            for C in [0.1, 1, 10, 100]:\n",
        "\n",
        "                log_reg = linear_model.LogisticRegression(C = C, max_iter=1000)\n",
        "                log_reg.fit(self.trainX, self.trainY[idx])\n",
        "                development_accuracy = log_reg.score(self.devX, self.devY[idx])\n",
        "                if development_accuracy > best_dev_accuracy:\n",
        "                    best_dev_accuracy=development_accuracy\n",
        "                    best_model=log_reg\n",
        "\n",
        "\n",
        "            self.log_regs[idx]=best_model\n",
        "\n",
        "    def test(self):\n",
        "        cor=tot=0\n",
        "        counts=Counter()\n",
        "        preds=[None]*(len(self.ordinal_values)-1)\n",
        "        for idx, ordinal_value in enumerate(self.ordinal_values[:-1]):\n",
        "            preds[idx]=self.log_regs[idx].predict_proba(self.testX)[:,1]\n",
        "\n",
        "        preds=np.array(preds)\n",
        "\n",
        "        for data_point in range(len(preds[0])):\n",
        "\n",
        "\n",
        "            ordinal_preds=np.zeros(len(self.ordinal_values))\n",
        "            for ordinal in range(len(self.ordinal_values)-1):\n",
        "                if ordinal == 0:\n",
        "                    ordinal_preds[ordinal]=1-preds[ordinal][data_point]\n",
        "                else:\n",
        "                    ordinal_preds[ordinal]=preds[ordinal-1][data_point]-preds[ordinal][data_point]\n",
        "\n",
        "            ordinal_preds[len(self.ordinal_values)-1]=preds[len(preds)-1][data_point]\n",
        "\n",
        "            prediction=np.argmax(ordinal_preds)\n",
        "            counts[prediction]+=1\n",
        "            if prediction == self.ordinal_values.index(self.orig_testY[data_point]):\n",
        "                cor+=1\n",
        "            tot+=1\n",
        "\n",
        "        return cor/tot\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "kUG3XnXJ5r60"
      },
      "outputs": [],
      "source": [
        "def binary_bow_featurize(text):\n",
        "    feats = {}\n",
        "    words = nltk.word_tokenize(text)\n",
        "\n",
        "    for word in words:\n",
        "        word=word.lower()\n",
        "        feats[word]=1\n",
        "\n",
        "    return feats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Yg9_KPUm7kdY"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "def tfidf_featurize(text):\n",
        "    feats = {}\n",
        "    words = nltk.word_tokenize(text.lower())\n",
        "    word_counts = Counter(words)\n",
        "    total_words = sum(word_counts.values())\n",
        "\n",
        "    for word in word_counts:\n",
        "        feats[word] = word_counts[word] / total_words\n",
        "\n",
        "    return feats\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "KKXa36JG5r61"
      },
      "outputs": [],
      "source": [
        "def confidence_intervals(accuracy, n, significance_level):\n",
        "    critical_value=(1-significance_level)/2\n",
        "    z_alpha=-1*norm.ppf(critical_value)\n",
        "    se=math.sqrt((accuracy*(1-accuracy))/n)\n",
        "    return accuracy-(se*z_alpha), accuracy+(se*z_alpha)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ExS7k9QC5r61"
      },
      "outputs": [],
      "source": [
        "def run(trainingFile, devFile, testFile, ordinal_values, featurizer): # added featurizer\n",
        "    trainX, trainY, orig_trainY = load_ordinal_data(trainingFile, ordinal_values)\n",
        "    devX, devY, orig_devY = load_ordinal_data(devFile, ordinal_values)\n",
        "    testX, testY, orig_testY = load_ordinal_data(testFile, ordinal_values)\n",
        "\n",
        "    # --- Select Classifier based on featurizer ---\n",
        "    if featurizer == tfidf_featurize:\n",
        "        classifier = OrdinalClassifierTFIDF( # Use the new class\n",
        "            ordinal_values,\n",
        "            featurizer, # Pass tfidf_featurize (which calculates TF)\n",
        "            trainX, trainY,\n",
        "            devX, devY,\n",
        "            testX, testY,\n",
        "            orig_trainY, orig_devY, orig_testY\n",
        "        )\n",
        "    else:\n",
        "        classifier = OrdinalClassifier( # Use the original class\n",
        "            ordinal_values,\n",
        "            featurizer,\n",
        "            trainX, trainY,\n",
        "            devX, devY,\n",
        "            testX, testY,\n",
        "            orig_trainY, orig_devY, orig_testY\n",
        "        )\n",
        "\n",
        "    classifier.train()\n",
        "    accuracy = classifier.test()\n",
        "\n",
        "    lower, upper = confidence_intervals(accuracy, len(testY[0]), 0.95)\n",
        "    print(\"Test accuracy for best dev model: %.3f, 95%% CIs: [%.3f %.3f]\" % (accuracy, lower, upper))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMzfsNSX5r62",
        "outputId": "7a1bcd47-29e2-4ff8-af76-403aa4c29c58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running with Bag of Words:\n",
            "Test accuracy for best dev model: 0.240, 95% CIs: [0.156 0.324]\n",
            "\n",
            "Running with TF:\n",
            "Test accuracy for best dev model: 0.280, 95% CIs: [0.192 0.368]\n"
          ]
        }
      ],
      "source": [
        "trainingFile = \"splits/train.txt\"\n",
        "devFile = \"splits/dev.txt\"\n",
        "testFile = \"splits/test.txt\"\n",
        "\n",
        "ordinal_values=[\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\"]\n",
        "\n",
        "print(\"Running with Bag of Words:\")\n",
        "run(trainingFile, devFile, testFile, ordinal_values, binary_bow_featurize)\n",
        "\n",
        "print(\"\\nRunning with TF:\")\n",
        "run(trainingFile, devFile, testFile, ordinal_values, tfidf_featurize)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8GFbUglLl1U"
      },
      "source": [
        "Default Bag of Words Accuracy: `0.240, 95% CIs: [0.156 0.324]`\n",
        "\n",
        "TF-IDF Accuracy: `0.280, 95% CIs: [0.192 0.368]`"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}